#!/usr/bin/env python3
"""
Script pour lister tous les mod√®les Gemini disponibles via l'API et filtrer les plus pertinents.
"""

import os
import requests
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

def list_all_gemini_models():
    """Liste tous les mod√®les Gemini disponibles."""
    api_key = os.getenv('GEMINI_API_KEY')
    
    # Si pas dans .env, essayer de r√©cup√©rer depuis la base de donn√©es
    if not api_key:
        try:
            import sqlite3
            conn = sqlite3.connect('database/ai_prompts.db')
            cursor = conn.cursor()
            cursor.execute("SELECT api_key FROM ai_credentials WHERE provider_name = 'gemini'")
            row = cursor.fetchone()
            if row:
                api_key = row[0]
                print(f"   ‚úì Cl√© API r√©cup√©r√©e depuis la base de donn√©es")
            conn.close()
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur lors de la lecture de la base: {e}")
    
    if not api_key:
        print("‚ùå Erreur: GEMINI_API_KEY non trouv√©e")
        print("   V√©rifiez:")
        print("   1. Fichier .env avec GEMINI_API_KEY=...")
        print("   2. Configuration dans l'interface GUI (onglet IA)")
        exit(1)
    
    print("üîç R√©cup√©ration de la liste des mod√®les Gemini...")
    print(f"   Cl√© API: {api_key[:8]}...{api_key[-4:]}")
    print()
    
    try:
        # Utiliser l'API REST pour lister les mod√®les
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
        response = requests.get(url)
        response.raise_for_status()
        
        data = response.json()
        models_data = data.get('models', [])
        
        print(f"üì¶ {len(models_data)} mod√®le(s) trouv√©(s) au total")
        print()
        
        # Organiser par cat√©gorie
        text_generation = []
        embedding_models = []
        vision_models = []
        other_models = []
        
        for model in models_data:
            model_name = model.get('name', '').replace('models/', '')
            
            # Filtrer par type
            if 'embed' in model_name.lower():
                embedding_models.append(model_name)
            elif 'vision' in model_name.lower() or 'imagen' in model_name.lower():
                vision_models.append(model_name)
            elif 'gemini' in model_name.lower():
                # Mod√®les de g√©n√©ration de texte
                text_generation.append(model_name)
            else:
                other_models.append(model_name)
        
        # Afficher les cat√©gories
        print("=" * 80)
        print("üìù MOD√àLES DE G√âN√âRATION DE TEXTE (Pertinents pour nous)")
        print("=" * 80)
        for model_name in sorted(text_generation):
            print(f"  ‚úì {model_name}")
        
        print()
        print("=" * 80)
        print("üö´ MOD√àLES D'EMBEDDING (√Ä retirer)")
        print("=" * 80)
        for model_name in sorted(embedding_models):
            print(f"  ‚úó {model_name}")
        
        print()
        print("=" * 80)
        print("üö´ MOD√àLES VISION/IMAGE (√Ä retirer)")
        print("=" * 80)
        for model_name in sorted(vision_models):
            print(f"  ‚úó {model_name}")
        
        if other_models:
            print()
            print("=" * 80)
            print("‚ùì AUTRES MOD√àLES")
            print("=" * 80)
            for model_name in sorted(other_models):
                print(f"  ? {model_name}")
        
        print()
        print("=" * 80)
        print("üéØ MOD√àLES RECOMMAND√âS POUR NOUS")
        print("=" * 80)
        
        # Filtrer les mod√®les recommand√©s
        recommended = []
        for model_name in text_generation:
            model_lower = model_name.lower()
            # Garder uniquement les mod√®les r√©cents et pertinents
            if any(version in model_lower for version in ['2.0', '2.5', '3.0', '1.5']):
                if 'flash' in model_lower or 'pro' in model_lower:
                    # Exclure les variantes sp√©ciales non pertinentes
                    if not any(exclude in model_lower for exclude in ['thinking', 'code', 'vision']):
                        recommended.append(model_name)
        
        # Trier par version (plus r√©cent en premier)
        def sort_key(name):
            import re
            match = re.search(r'gemini-(\d+)\.(\d+)', name.lower())
            if match:
                major, minor = int(match.group(1)), int(match.group(2))
                # Privil√©gier flash sur pro
                is_flash = 'flash' in name.lower()
                return (major, minor, 0 if is_flash else 1)
            return (0, 0, 0)
        
        recommended.sort(key=sort_key, reverse=True)
        
        for i, model_name in enumerate(recommended, 1):
            marker = "‚≠ê" if i == 1 else "‚úì"
            default_text = " (D√âFAUT RECOMMAND√â)" if i == 1 else ""
            print(f"  {marker} {model_name}{default_text}")
        
        print()
        print("=" * 80)
        print("üìã R√âSUM√â")
        print("=" * 80)
        print(f"  Total mod√®les: {len(models_data)}")
        print(f"  G√©n√©ration texte: {len(text_generation)}")
        print(f"  Embedding (√† retirer): {len(embedding_models)}")
        print(f"  Vision/Image (√† retirer): {len(vision_models)}")
        print(f"  Recommand√©s: {len(recommended)}")
        
        print()
        print("=" * 80)
        print("üíæ CONFIGURATION POUR ai_config.json")
        print("=" * 80)
        print('"gemini": {')
        print(f'  "default": "{recommended[0]}",')
        print('  "available": [')
        for i, model_name in enumerate(recommended):
            comma = "," if i < len(recommended) - 1 else ""
            print(f'    "{model_name}"{comma}')
        print('  ]')
        print('}')
        
        return recommended
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des mod√®les: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == "__main__":
    list_all_gemini_models()
